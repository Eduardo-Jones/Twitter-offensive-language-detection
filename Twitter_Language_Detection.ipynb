{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading/Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_txt_train= []\n",
    "y_train = []\n",
    "\n",
    "# Loading data from CSVs.\n",
    "\n",
    "# 1. Load the training datasets into two lists (X_txt_train will be a list of strings; y_train)\n",
    "file_train = open(\"train.tsv\",  encoding=\"utf8\")\n",
    "\n",
    "reader_train = csv.reader(file_train,delimiter=\"\\t\")\n",
    "\n",
    "for row in reader_train:\n",
    "    y = row[2]\n",
    "    X_txt = row[1]\n",
    "    X_txt_train.append(X_txt)\n",
    "    y_train.append(y)\n",
    "    \n",
    "# 2. Load the test datasets into two lists (X_txt_test will be a list of strings; y_test)    \n",
    "file_test = open(\"test.tsv\", encoding=\"utf8\")\n",
    "reader_test = csv.reader(file_test,delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for row in reader_test:\n",
    "    test_data.append(row)  \n",
    "\n",
    "X_txt_train, X_txt_test, y_train, y_test = train_test_split(X_txt_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LexiconClassifier():\n",
    "    def __init__(self):\n",
    "            \"\"\"\n",
    "                Initalize the Lexicon classifer by loading lexicons.\n",
    "            \"\"\"\n",
    "            self.offensive_language = set()\n",
    "            with open('bad-words.txt', encoding = 'utf-8') as iFile:\n",
    "                for row in iFile:\n",
    "                    self.offensive_language.add(row.strip())\n",
    "            self.target = set()\n",
    "            with open('names.txt', encoding='utf-8') as iFile:\n",
    "                for row in iFile: # add if statement here to break up the Classifiers???\n",
    "                    self.target.add(row.lower().strip())\n",
    "                    \n",
    "\n",
    "    def predict(self, tweet):\n",
    "            \"\"\"\n",
    "                Returns a prediction for a string in tweet.\n",
    "                Returns:\n",
    "                pred -- a string (\"TIN\", \"OFF\", \"NOT\")  # this is for the classifier portion\n",
    "            \"\"\"\n",
    "           \n",
    "                    \n",
    "            num_offensive_words = 0 # OFF\n",
    "            num_targeted_offensive_words = 0  # TIN\n",
    "            cap_words = 0\n",
    "            \n",
    "            for word in tweet.split():\n",
    "                if word.lower() in self.offensive_language:\n",
    "                    num_offensive_words += 1\n",
    "                if word.lower() in self.target :\n",
    "                    num_targeted_offensive_words +=1\n",
    "                if word.isupper()== True and word not in [\"@USER\", \"NOT\",\"TIN\",\"OFF\",\"I\"]:\n",
    "                    cap_words +=1\n",
    "            pred = \"NOT\"        \n",
    "            #If tweet contains offensive words and target words, label as 'TIN'\n",
    "            if num_offensive_words >0 and num_targeted_offensive_words >0:\n",
    "                pred = \"TIN\"\n",
    "            #If there's an offensive word, label it offensive\n",
    "            elif num_offensive_words > 0:\n",
    "                pred = 'OFF'\n",
    "            return pred\n",
    "        \n",
    "    def count_offensive(self, tweet):\n",
    "        \n",
    "            num_offensive_words = 0\n",
    "            for word in tweet.split():\n",
    "                if word.lower() in self.offensive_language:\n",
    "                    num_offensive_words += 1\n",
    "                    \n",
    "            return num_offensive_words\n",
    "\n",
    "    def count_target(self, tweet):\n",
    "        \n",
    "            num_targeted_offensive_words = 0\n",
    "            for word in tweet.split():\n",
    "                if word.lower() in self.target:\n",
    "                    num_targeted_offensive_words += 1\n",
    "                    \n",
    "            return num_targeted_offensive_words\n",
    "\n",
    "    def count_cap(self, tweet):\n",
    "        \n",
    "            num_cap_words = 0\n",
    "            for word in tweet.split():\n",
    "                if word.isupper()== True and self not in [\"@USER\", \"NOT\",\"TIN\",\"OFF\",\"I\"]:\n",
    "                    num_cap_words +=1\n",
    "            return num_cap_words\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score with rule based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6588\n",
      "Recall: 0.6588\n",
      "F1: 0.6588\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 1. Instatiate that class\n",
    "myclfr = LexiconClassifier()\n",
    "lex_test_preds = []\n",
    "\n",
    "# Loop over X_txt_test\n",
    "#    for each string in X_txt_test (i.e., for each item in the list), pass it to LexiconClassifiers .predict() method\n",
    "#    append the prediction to lex_test_preds\n",
    "for i in X_txt_test:\n",
    "    lex_test_preds.append(myclfr.predict(i))\n",
    "\n",
    "\n",
    "precision = precision_score(lex_test_preds, y_test, average = 'micro') # Get scores using lex_test_preds and y_test with the precision_score method\n",
    "recall = recall_score(lex_test_preds, y_test, average = 'micro') # Get scores using lex_test_preds and y_test with the recall_score method\n",
    "f1 = f1_score(lex_test_preds, y_test, average = 'micro')# Get scores using lex_test_preds and y_test with the f1_score method\n",
    "\n",
    "print(\"Precision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1: {:.4f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score with CountVectorizer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score 0.7220587586358138\n",
      "Best Params: {'clf__C': 0.1, 'vec__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('vec', CountVectorizer()),\n",
    "                ('clf', LinearSVC(random_state = 42))])\n",
    "\n",
    "\n",
    "params = {\"clf__C\": [0.01, 0.1, 1.],\n",
    "         \"vec__ngram_range\": [(1,1),(1,2)]}\n",
    "\n",
    "clf = GridSearchCV(pipe,params, cv=2, scoring = 'f1_micro')\n",
    "\n",
    "clf.fit(X_txt_train, y_train)\n",
    "\n",
    "Score = clf.predict(X_txt_test)\n",
    "\n",
    "print('Best Score', clf.best_score_)\n",
    "print('Best Params:', clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score with both(stacked) rule based features and CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lexicon_features = [] # Initailze to an empty list. This will be a list of lists\n",
    "X_test_lexicon_features = [] #  Initailze to an empty list. This will be a list of lists\n",
    "\n",
    "for i in X_txt_train:\n",
    "    X_train_lexicon_features.append([myclfr.count_offensive(i), myclfr.count_target(i),myclfr.count_cap(i)])\n",
    "\n",
    "for i in X_txt_test:\n",
    "    X_test_lexicon_features.append([myclfr.count_offensive(i), myclfr.count_target(i),myclfr.count_cap(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with Lexicon 0.7310293835957552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack, coo_matrix\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "vec = CountVectorizer(ngram_range =(1,1))\n",
    "\n",
    "X_train_w_lex = vec.fit_transform(X_txt_train) # This will be the matrix from CountVectorizer (X_txt_train)\n",
    "X_test_w_lex = vec.transform(X_txt_test)\n",
    "\n",
    "X_train_lexicon_features = np.array(X_train_lexicon_features)\n",
    "X_test_lexicon_features = np.array(X_test_lexicon_features)\n",
    "\n",
    "X_train_w_lex = hstack([X_train_lexicon_features,X_train_w_lex]).toarray()\n",
    "X_test_w_lex = hstack([X_test_lexicon_features, X_test_w_lex]).toarray()\n",
    "\n",
    "\n",
    "SVC = LinearSVC()\n",
    "params = {'C':[0.01, 0.1, 1.]}\n",
    "clf = GridSearchCV(SVC, params, cv = 5)\n",
    "clf.fit(X_train_w_lex, y_train)\n",
    "lexicon_pred = clf.predict(X_test_w_lex)\n",
    "print('Score with Lexicon', clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating dataframe to view test-from-train results\n",
    "\n",
    "df_ruleCountVec = pd.DataFrame({\"tweet\" : X_txt_test, \"actual\" : y_test})\n",
    "df_ruleCountVec['predictions'] = lexicon_pred.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>actual</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER @USER  -its quite obvious the  morons at...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER i’m weak 😂😂.. Shit must have been really...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Who the hell does @USER think he is to s...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Just because his best stats season was a...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58 factory workers massacred in Salt Lake City...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@USER Oh my heart! She is beautiful. MUCH more...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@USER URL  And this explains why he is disresp...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@USER Trump will blame it on the immigrants fo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@USER She is so proud</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet actual predictions\n",
       "0  @USER @USER  -its quite obvious the  morons at...    TIN         TIN\n",
       "1  @USER @USER @USER @USER @USER @USER @USER @USE...    NOT         NOT\n",
       "2  @USER i’m weak 😂😂.. Shit must have been really...    TIN         TIN\n",
       "3  @USER Who the hell does @USER think he is to s...    NOT         TIN\n",
       "4  @USER Just because his best stats season was a...    TIN         NOT\n",
       "5  58 factory workers massacred in Salt Lake City...    NOT         NOT\n",
       "6  @USER Oh my heart! She is beautiful. MUCH more...    NOT         NOT\n",
       "7  @USER URL  And this explains why he is disresp...    TIN         TIN\n",
       "8  @USER Trump will blame it on the immigrants fo...    NOT         TIN\n",
       "9                              @USER She is so proud    NOT         NOT"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ruleCountVec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating dataset for false positives and negatives\n",
    "df_ruleCountVec_FALSE = df_ruleCountVec[~(df_ruleCountVec['actual']==df_ruleCountVec['predictions'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>actual</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER Who the hell does @USER think he is to s...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@USER Just because his best stats season was a...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@USER Trump will blame it on the immigrants fo...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@USER No prison time for you. You're going to ...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@USER Look at this chill as fuck bearded drago...</td>\n",
       "      <td>UNT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>@USER He is still eating and talking about p**...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>@USER Dear Paul McFartney-  You had us at Beat...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>@USER Nanos Poll .........Liberals 41.1 Conser...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>@USER Maybe because you’ve provided a play for...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>TIN</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet actual predictions\n",
       "3   @USER Who the hell does @USER think he is to s...    NOT         TIN\n",
       "4   @USER Just because his best stats season was a...    TIN         NOT\n",
       "8   @USER Trump will blame it on the immigrants fo...    NOT         TIN\n",
       "14  @USER No prison time for you. You're going to ...    TIN         NOT\n",
       "22  @USER Look at this chill as fuck bearded drago...    UNT         TIN\n",
       "30  @USER He is still eating and talking about p**...    TIN         NOT\n",
       "32  @USER Dear Paul McFartney-  You had us at Beat...    TIN         NOT\n",
       "33  @USER Nanos Poll .........Liberals 41.1 Conser...    NOT         TIN\n",
       "34  @USER Maybe because you’ve provided a play for...    TIN         NOT\n",
       "36  @USER @USER @USER @USER @USER @USER @USER @USE...    TIN         NOT"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ruleCountVec_FALSE[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying to Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing test_data into pd Dataframe for easy changes\n",
    "td = pd.DataFrame(test_data, columns=['id', 'tweet','pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_lexicon_features = [] # Initailze to an empty list. This will be a list of lists\n",
    "\n",
    "for i in td['tweet']: # this orignally was reading 'test_data[1]' which is the row, now this reads whole 'tweet' column\n",
    "    test_data_lexicon_features.append([myclfr.count_offensive(i), myclfr.count_target(i),myclfr.count_cap(i)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 8, 2],\n",
       " [1, 7, 1],\n",
       " [1, 2, 7],\n",
       " [0, 2, 3],\n",
       " [0, 2, 1],\n",
       " [1, 7, 2],\n",
       " [0, 14, 4],\n",
       " [1, 4, 2],\n",
       " [0, 1, 1],\n",
       " [0, 5, 5]]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_lexicon_features[:10] # checking to see the lexicon counts for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with Lexicon 0.7310293835957552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse import hstack, coo_matrix\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "test_data_w_lex = vec.transform(td['tweet']) #changed to read tweet column instead of 'test_data[1] row'\n",
    "\n",
    "test_data_lexicon_features = np.array(test_data_lexicon_features)\n",
    "\n",
    "\n",
    "test_data_w_lex = hstack([test_data_lexicon_features,test_data_w_lex]).toarray()\n",
    "\n",
    "SVC = LinearSVC()\n",
    "params = {'C':[0.01, 0.1, 1.]}\n",
    "clf = GridSearchCV(SVC, params, cv = 5)\n",
    "clf.fit(X_train_w_lex, y_train)\n",
    "test_data_pred = clf.predict(test_data_w_lex)\n",
    "print('Score with Lexicon', clf.best_score_) # Not sure if we need this since it's referring to the best\n",
    "                                             # score/Lexicon obtianed from training data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOT', 'TIN', 'NOT', ..., 'NOT', 'TIN', 'NOT'], dtype='<U3')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_pred # checking the array of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "td['prediction']=test_data_pred.reshape(-1,1) #adding new 'prediction' array and reshaping into column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>pred</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41567</td>\n",
       "      <td>@USER Nancy Lee Grahn You Are Awesome! I have ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19123</td>\n",
       "      <td>@USER She is a Skrull. Enemy of The Kree. The ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79672</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER Exce...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29055</td>\n",
       "      <td>@USER @USER @USER You are so beautiful♡</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32479</td>\n",
       "      <td>@USER This is what happens when liberals get i...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42594</td>\n",
       "      <td>@USER @USER Daniels said her job does not refl...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95697</td>\n",
       "      <td>@USER No longer on guard, Marie smiles warmly....</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>96084</td>\n",
       "      <td>@USER Gun control is  omportant. It should not...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>77548</td>\n",
       "      <td>@USER Antifa girl of the month centrefold!</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>62926</td>\n",
       "      <td>@USER @USER @USER @USER Tweet is directed at h...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53633</td>\n",
       "      <td>@USER Oh well yes goes without saying you are ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14182</td>\n",
       "      <td>@USER Good!!! MAGA</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49199</td>\n",
       "      <td>@USER #AmazonPets  This is bonnie she is 2 yea...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35683</td>\n",
       "      <td>/63 More evidence Liberals only goal is to sab...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>43602</td>\n",
       "      <td>@USER @USER She’s a class act isn’t she. Kim t...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33000</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>94730</td>\n",
       "      <td>@USER @USER @USER Where is VAN? She is ARMY wh...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11166</td>\n",
       "      <td>@USER why do conservatives have such a hard ti...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>84074</td>\n",
       "      <td>@USER @USER @USER Fk River you are a sick indi...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>42883</td>\n",
       "      <td>@USER Gotta keep that gun control law to get t...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>43215</td>\n",
       "      <td>@USER @USER What a wonderful caring president ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20583</td>\n",
       "      <td>@USER Anyone else getting a different idea of ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>78116</td>\n",
       "      <td>@USER   you are worthy 💪🏾 💯URL</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43409</td>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USE...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>TIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>84054</td>\n",
       "      <td>@USER @USER @USER Supporting an apartheid stat...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              tweet pred prediction\n",
       "0   41567  @USER Nancy Lee Grahn You Are Awesome! I have ...  NOT        NOT\n",
       "1   19123  @USER She is a Skrull. Enemy of The Kree. The ...  NOT        TIN\n",
       "2   79672  @USER @USER @USER @USER @USER @USER @USER Exce...  NOT        NOT\n",
       "3   29055            @USER @USER @USER You are so beautiful♡  NOT        NOT\n",
       "4   32479  @USER This is what happens when liberals get i...  NOT        NOT\n",
       "5   42594  @USER @USER Daniels said her job does not refl...  NOT        TIN\n",
       "6   95697  @USER No longer on guard, Marie smiles warmly....  NOT        NOT\n",
       "7   96084  @USER Gun control is  omportant. It should not...  NOT        NOT\n",
       "8   77548         @USER Antifa girl of the month centrefold!  NOT        NOT\n",
       "9   62926  @USER @USER @USER @USER Tweet is directed at h...  NOT        NOT\n",
       "10  53633  @USER Oh well yes goes without saying you are ...  NOT        NOT\n",
       "11  14182                                 @USER Good!!! MAGA  NOT        NOT\n",
       "12  49199  @USER #AmazonPets  This is bonnie she is 2 yea...  NOT        NOT\n",
       "13  35683  /63 More evidence Liberals only goal is to sab...  NOT        TIN\n",
       "14  43602  @USER @USER She’s a class act isn’t she. Kim t...  NOT        NOT\n",
       "15  33000  @USER @USER @USER @USER @USER @USER @USER @USE...  NOT        TIN\n",
       "16  94730  @USER @USER @USER Where is VAN? She is ARMY wh...  NOT        NOT\n",
       "17  11166  @USER why do conservatives have such a hard ti...  NOT        NOT\n",
       "18  84074  @USER @USER @USER Fk River you are a sick indi...  NOT        TIN\n",
       "19  42883  @USER Gotta keep that gun control law to get t...  NOT        NOT\n",
       "20  43215  @USER @USER What a wonderful caring president ...  NOT        NOT\n",
       "21  20583  @USER Anyone else getting a different idea of ...  NOT        NOT\n",
       "22  78116                     @USER   you are worthy 💪🏾 💯URL  NOT        NOT\n",
       "23  43409  @USER @USER @USER @USER @USER @USER @USER @USE...  NOT        TIN\n",
       "24  84054  @USER @USER @USER Supporting an apartheid stat...  NOT        NOT"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td[:25] #checking test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                              tweet pred prediction\n",
      "10  53633  @USER Oh well yes goes without saying you are ...  NOT        NOT\n",
      "11  14182                                 @USER Good!!! MAGA  NOT        NOT\n",
      "12  49199  @USER #AmazonPets  This is bonnie she is 2 yea...  NOT        NOT\n",
      "13  35683  /63 More evidence Liberals only goal is to sab...  NOT        TIN\n",
      "14  43602  @USER @USER She’s a class act isn’t she. Kim t...  NOT        NOT\n"
     ]
    }
   ],
   "source": [
    "print(td[10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data_w_lex)\n",
    "len(test_data)\n",
    "\n",
    "print(test_data_w_lex)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train_w_lex)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24008/2205366775.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#y_train.append(y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mPrediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "Prediction = []\n",
    "Actual = []\n",
    "for row in test_data:\n",
    "    Actual = row[2]\n",
    "    #Prediction.append(Actual)\n",
    "    #y_train.append(y)\n",
    "for row in td:\n",
    "    Prediction = row[3]\n",
    "    \n",
    "    \n",
    "#confusion_matrix(Actual, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.array(Actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT\n"
     ]
    }
   ],
   "source": [
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8473"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Actual)\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 6 2 ... 0 0 0]\n",
      " [0 5 9 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [2 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 2 3 ... 0 0 0]]\n",
      "8473\n",
      "8473\n",
      "2648\n"
     ]
    }
   ],
   "source": [
    "type(X_test_w_lex)\n",
    "print(X_test_w_lex)\n",
    "type(y_train)\n",
    "print(len(y_train))\n",
    "type(X_train_w_lex)\n",
    "print(len(X_train_w_lex))\n",
    "type(test_data_w_lex)\n",
    "print(len(test_data_w_lex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 10  3]\n",
      " [ 0  0  1]\n",
      " [ 1  5  1]\n",
      " ...\n",
      " [ 0  2  2]\n",
      " [ 0  2  2]\n",
      " [ 0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_lexicon_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
